# ArtificialVision


# Assistive Machine Learning Approaches for Simulating Human Psychophysical Test of Low-Resolution Artificial Vision
Na Min An, Hyeonhee Roh, Sein Kim, Jae Hun Kim, and Maesoon Im
<br />


## Main figure
<p align="center" width="100%"><img src="https://github.com/namin-an/ArtificialVision/blob/main/images/Fig1.png"></img></p>   
ğŸŒƒ: https://pixabay.com
ğŸŒ: https://www.flaticon.com
<br />


## Abstract video
[![IMAGE ALT TEXT](https://github.com/namin-an/ArtificialVision/blob/main/images/cover.png)](https://www.youtube.com/watch?v=kHdlyUNurds)
<br />


## Datasets
> Machine data: [AI Hub K-face dataset](https://aihub.or.kr)   
> Human data: [Ours](https://github.com/namin-an/ArtificialVision/tree/main/data/Human_Expert/211202)


## Usage
1. Clone this repository.
```
git clone https://github.com/namin-an/ArtificialVision.git   
cd ArtificialVision   
```


2. Setup the conda environment (python 3.9.13).
```
conda create -n artificialvision python=3.9   
conda activate artificialvision   
pip install -r requirements.txt   
```


3. Preprocess the K-face datasets by following the step-by-step process from the jupyter notebooks below:

    - Step 1. Unzip all the original files.
    ```
    cd Processing
    unzipAIHubData.py
    ```

    - Step 2. SGBt 4,972 images that are recognizable and crop them into the dimension of 128 x 128 following the code steps written in [Processing/selCropPhotos.ipynb](https://github.com/namin-an/ArtificialVision/blob/main/Preprocessing/selCropPhotos.ipynb)

    - Step 3. Make customized masks for K-Face datasets using the U-Net pretrained on [CelebA-HQ dataset](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) and remove noisy backgrounds utilizing [Processing/genMaskremBack.ipynb](https://github.com/namin-an/ArtificialVision/blob/main/Preprocessing/genMaskremBack.ipynb)

    - Step 4. Make low-resolution phosphene images (contrast enhancement + grayscaling + pixelation + phosphenizing) using [Processing/downsamp.ipynb](https://github.com/namin-an/ArtificialVision/blob/main/Preprocessing/downsamp.ipynb)
          

4. Build and train machine learning (ML) models with original high-resolution images and evaluate their performances on low-resolution images by running the shell scripts placed under [scripts/](https://github.com/namin-an/ArtificialVision/tree/main/scripts).



5. (OPTIONAL) Reproduce several figures from the manuscript ([Visualization/](https://github.com/namin-an/ArtificialVision/tree/main/Visualization))  
<br />


## Code structure
```
â”œâ”€â”€ Preprocessing (usage #3)
â”‚   â”œâ”€â”€ unzipAIHubData.py
â”‚   â”œâ”€â”€ selCropPhotos.ipynb (Fig. S7b-c)
â”‚   â”œâ”€â”€ genMaskremBack.ipynb (Fig. S7d and the first three steps in Fig. S7e)
â”‚   â”œâ”€â”€ downsamp.ipynb (the last three steps in Fig. S7e, S7f, and S7g)
â”‚
â”œâ”€â”€ main.py (usage #4)
â”œâ”€â”€ loadData.py  
â”œâ”€â”€ expModels.py 
â”œâ”€â”€ mypackages
â”‚   â”œâ”€â”€ pytorchtools.py
â”œâ”€â”€ scripts (training options)
â”‚   â”œâ”€â”€ [model_type]_[loss function type]_[facial class size]_[data type].sh
â”‚
â”œâ”€â”€ Visualization (optional usage #5)
â”‚   â”œâ”€â”€ ColormapsPIXGS.ipynb (Figs. 1a, S1a, 3a, S3a, Ext. Data Fig. 1a, and 1b)
â”‚   â”œâ”€â”€ Parallel.ipynb (Figs. 1e and S1e) 
â”‚   â”œâ”€â”€ Prediction.ipynb (Figs 1e, S1e, 3a-c, and S3a-c)  
â”‚   â”œâ”€â”€ Wordclouds.ipynb (Figs 1c, S1c, 5d, and S5d)
â”‚
â”œâ”€â”€ checkpoints
â”‚   â”œâ”€â”€ saved-unet_model-02-0.09.hdf5 (usage #3: U-Net - can be given if requested)
â”‚   â”œâ”€â”€ Checkpoint_3.h5 (usage #5: Shallow ML model for non-Gaussian-blurred version)
â”‚   â”œâ”€â”€ Checkpoint_4.h5 (usage #5: Shallow ML model for Gaussian-blurred version)
```
<br />


## Adaptations
> Grad-CAM [jacobgil/pytorch_grad_cam](https://github.com/jacobgil/pytorch-grad-cam) (Figs. 5a and S5a)  
> Early-stopping [Bjarten/early-stopping-pytorch](https://github.com/Bjarten/early-stopping-pytorch)  
<br />


## Citation
If you want to report the results of our method or implement the framework, please cite as follows:   
```
@INPROCEEDINGS{?,
  author    = {An, Na Min and Roh, Hyeonhee and Kim, Sein and Kim, Jae Hun and Im, Maesoon},
  booktitle = {?}, 
  title     = {Assistive Machine Learning Approaches for Simulating Human Psychophysical Test of Low-Resolution Artificial Vision},
  year      = {2023},
  volume    = {?},
  pages     = {?},
  doi       = {?}
}
```
<br />


## Contact
If you have any questions regarding the code or paper, feel free to reach us at:
```
namin0202@gmail.com (Na Min An)
```