{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_type = 'elec'\n",
    "avg_hum = True\n",
    "base_path = f'[USER_PATH]\\\\ArtificialVision'\n",
    "\n",
    "num_class = 16\n",
    "if test_type == 'opt':\n",
    "  sel_ppl = list(range(300, 309)) + list(range(400, 408)) + [611]\n",
    "  sel_mc = [1, 2, 3]\n",
    "elif test_type == 'elec':\n",
    "  sel_ppl = [499, 500] + list(range(502, 509)) + list(range(601, 607)) + list(range(608, 611)) \n",
    "  sel_mc = [4, 5, 6]\n",
    "\n",
    "quesdata_files = glob(f'{base_path}\\\\data\\\\Question_Banks_AI_Hub_final\\\\16classes\\\\set0\\\\*')\n",
    "humdata_path = glob(f'{base_path}\\\\data\\\\Human_Expert\\\\211202')[0]\n",
    "humsub_path = glob(f'{base_path}\\\\data\\\\210827_ANNA_Removing_uncontaminated_data.csv')[0]\n",
    "answer_path = glob(f'{base_path}\\\\data\\\\211105_QAs_for_Set0_CNN_SVC_4classes_partial.csv')[0]\n",
    "testdata_path = glob(f'{base_path}\\\\data\\\\sample_for_dev_test_{test_type}')[0]\n",
    "fig_path = glob(f'{base_path}\\\\figures')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_df = pd.DataFrame()\n",
    "n = 9\n",
    "for i in range(1, 80*n+1, 80):\n",
    "    try:\n",
    "      j = i+79\n",
    "      temp_df = pd.read_csv(os.path.join(humdata_path, f'main_test({i}_{j}).csv'))\n",
    "      if i == 1:\n",
    "        pass\n",
    "      else:\n",
    "        temp_df = temp_df.rename(columns = {'유저식별아이디':'useless', 'MC구분':'useless', '성별':'useless', '나이':'useless', '학력':'useless'})\n",
    "      human_df = pd.concat([human_df, temp_df], axis=1)\n",
    "    except:\n",
    "      print(i)\n",
    "\n",
    "human_df = human_df[human_df['유저식별아이디'].isin(sel_ppl)]\n",
    "\n",
    "if avg_hum:\n",
    "  human_df = human_df[human_df['MC구분'].isin(sel_mc)]\n",
    "orig_human_df = human_df\n",
    "orig_human_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_df = pd.read_csv(answer_path)\n",
    "\n",
    "act_per_list, pix_list, gs_list, par_list = [], [], [], []\n",
    "for answer in answer_df['Answer']:\n",
    "    img, _ = answer.split('.jpg')\n",
    "    act_per, pix, gs, par = img.split('_')\n",
    "    \n",
    "    act_per_list.append(act_per)\n",
    "    pix_list.append(pix)\n",
    "    gs_list.append(gs)\n",
    "    par_list.append(par)\n",
    "\n",
    "answer_df['act_per'] = act_per_list\n",
    "answer_df['PIX'] = pix_list\n",
    "answer_df['GS'] = gs_list\n",
    "answer_df['par'] = par_list\n",
    "\n",
    "answer_df = answer_df[:80*n]\n",
    "answer_df = answer_df.T\n",
    "\n",
    "orig_answer_df = answer_df\n",
    "answer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessed Human Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_df = orig_human_df.copy()\n",
    "human_df = human_df.fillna(0)\n",
    "if avg_hum:\n",
    "    human_df['MC구분'] = human_df['MC구분'].astype(int)\n",
    "    human_df.index = human_df['MC구분']\n",
    "else:\n",
    "    human_df['유저식별아이디'] = human_df['유저식별아이디'].astype(int)\n",
    "    human_df.index = human_df['유저식별아이디']\n",
    "\n",
    "sel_col = []\n",
    "for (i, col) in enumerate(human_df.columns):\n",
    "    split = col.split('_')\n",
    "    if split[0] == '선택' and split[1] == 'A':\n",
    "        sel_col.append(col)\n",
    "    \n",
    "acc_df = human_df[sel_col]\n",
    "acc_df.columns = [n for n in range(acc_df.shape[1])]\n",
    "acc_df = acc_df.astype(int)\n",
    "\n",
    "for q in range(acc_df.shape[1]):\n",
    "    act_per = answer_df.loc['act_per'][q] \n",
    "    for s in range(acc_df.shape[0]):\n",
    "        pred_per = acc_df.iloc[s, q]\n",
    "        try:\n",
    "            if str(int(pred_per)) == str(int(act_per)):\n",
    "                acc_df.iloc[s, q] = 1\n",
    "            else:\n",
    "                acc_df.iloc[s, q] = 0\n",
    "        except:\n",
    "            acc_df.iloc[s, q] = 0\n",
    "\n",
    "acc_df.columns = answer_df.T['Answer']\n",
    "\n",
    "if avg_hum:\n",
    "    acc_df = acc_df.reset_index()\n",
    "    acc_df = acc_df.groupby('MC구분').mean()\n",
    "\n",
    "acc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type1_list = [''] # ['PCA', 'PCA', '', '']\n",
    "model_type2_list = ['CNN_SVC'] # ['SVC', 'LR', 'CNN_LR', 'CNN_SVC']\n",
    "seed_list = [22, 77, 2, 100, 81, 42, 7, 1, 55, 50] \n",
    "pix_order_list = ['16PIX', '24PIX', '32PIX', '64PIX', '128PIX']\n",
    "gs_order_list = ['2GS', '4GS', '6GS', '8GS', '16GS']\n",
    "\n",
    "df = pd.read_csv(humsub_path)\n",
    "l = list(range(df.shape[0]))\n",
    "n = 16\n",
    "random.seed(22)\n",
    "set_1 = random.sample(l, n)\n",
    "sets = [set_1]\n",
    "\n",
    "\n",
    "for (model_type1, model_type2) in zip(model_type1_list, model_type2_list):\n",
    "    model_type = model_type1 + model_type2\n",
    "    input_folder = [df.iloc[i, 0] for i in sets[0]] \n",
    "    assert len(input_folder) == 16\n",
    "    com_obj = itertools.combinations(input_folder, 16)\n",
    "    com_list = list(com_obj)\n",
    "\n",
    "    mac_df = pd.DataFrame()\n",
    "    for i in range(len(quesdata_files)):\n",
    "        data_path = quesdata_files[i]\n",
    "        seed = int(os.path.basename(data_path).split('d')[-1])\n",
    "\n",
    "        for n in range(len(os.listdir(data_path))):\n",
    "            print(seed, n)\n",
    "\n",
    "            preprocessed_data_path =  os.path.join(data_path, f'comb{n}') \n",
    "            high_analysis_path = os.path.join(preprocessed_data_path, f'High_Analysis_{test_type}')\n",
    "            \n",
    "            add_high_df = pd.read_csv(os.path.join(high_analysis_path, f'High_Level_Data_Analysis_{model_type1}_{model_type2}.csv'))\n",
    "            add_high_df['Hit Rate'] = add_high_df['correctness'].replace(['correct', 'wrong'], [1, 0]) \n",
    "            add_high_df = add_high_df[['file_name', 'actual_person', 'Hit Rate']]\n",
    "            add_high_df['actual_person'] = add_high_df['actual_person'].astype(int)\n",
    "            \n",
    "            img_list, hyperpar_list, par_list = [], [], []\n",
    "            for i in range(add_high_df.shape[0]):\n",
    "                file_name = add_high_df['file_name'][i].split('.')[0]\n",
    "                pix, gs, par = file_name.split('_')\n",
    "                per = add_high_df['actual_person'][i]\n",
    "                img = str(per) + '_' + str(pix) + '_' + str(gs) + '_' + str(par) + '.jpg'\n",
    "                img_list.append(img)\n",
    "                hyperpar_list.append(str(pix) + '_' + str(gs))\n",
    "                par_list.append(str(par))\n",
    "            add_high_df['img'] = img_list\n",
    "            add_high_df['hyperpar'] = hyperpar_list\n",
    "            add_high_df['par'] = par_list\n",
    "            \n",
    "            add_high_df = add_high_df[['img', 'hyperpar', 'par', 'Hit Rate']]\n",
    "        \n",
    "        add_high_df['Seed'] = [seed] * add_high_df.shape[0]\n",
    "        \n",
    "        mac_df = pd.concat([mac_df, add_high_df], axis=0)\n",
    "\n",
    "new_hyperpar_name_list = ['16PIX_2GS', '16PIX_4GS', '16PIX_8GS', \n",
    "                          '32PIX_2GS', '32PIX_4GS', '32PIX_8GS',  \n",
    "                          '64PIX_2GS', '64PIX_4GS', '64PIX_8GS']\n",
    "par_list = ['S001L1E01C4', 'S001L1E01C7', 'S001L1E01C10',\n",
    "            'S001L1E02C7',\n",
    "            'S001L1E03C7']\n",
    "mac_df = mac_df[mac_df['hyperpar'].isin(new_hyperpar_name_list)]\n",
    "mac_df = mac_df[mac_df['par'].isin(par_list)]\n",
    "\n",
    "mac_df = mac_df.pivot(index='Seed', columns='img', values='Hit Rate')\n",
    "\n",
    "mac_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Performances Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type1_list = ['', '', '', '', '', '', '', '', '', '', 'PCA', 'PCA'] \n",
    "model_type2_list = ['PIXEL_LR','PIXEL_SVC', 'CNN_LR', 'CNN_SVC', 'CNN_VggNet2', 'CNN_VggNet2_SVC', 'CNN_AlexNet2', 'CNN_AlexNet2_SVC', 'CNN_ResNet2', 'CNN_ResNet2_SVC', 'SVC', 'LR']\n",
    "\n",
    "for (model_type1, model_type2) in zip(model_type1_list, model_type2_list):\n",
    "    model_type = model_type1 + model_type2\n",
    "\n",
    "    high_df = pd.DataFrame()\n",
    "    for i in range(len(quesdata_files)):\n",
    "        data_path = quesdata_files[i]\n",
    "        preprocessed_data_path =  os.path.join(data_path, 'comb0') \n",
    "\n",
    "        high_analysis_path = os.path.join(preprocessed_data_path, f'High_Analysis_{test_type}')\n",
    "        try:\n",
    "            add_high_df = pd.read_csv(os.path.join(high_analysis_path, f'High_Level_Data_Analysis_{model_type1}_{model_type2}.csv'))\n",
    "            add_high_df['hit_rate'] = add_high_df['correctness'].replace(['correct', 'wrong'], [1, 0]) \n",
    "            high_df = pd.concat([high_df, add_high_df], axis=0)\n",
    "            high_df = high_df[['file_name', 'actual_person', 'hit_rate']]\n",
    "        except:\n",
    "            print(model_type, i, 'error')\n",
    "            pass\n",
    "            \n",
    "    image_list = []\n",
    "    for i, file_name in enumerate(high_df['file_name']):\n",
    "        face = high_df['actual_person'].iloc[i]\n",
    "        face = str(int(float(face)))\n",
    "        image_list.append(f'{face}_{file_name}')\n",
    "    high_df['image'] = image_list\n",
    "\n",
    "    high_df = high_df[['image', 'hit_rate']]\n",
    "\n",
    "    old_high_df_cols = high_df.columns\n",
    "    new_high_df_cols = [f'{model_type}_' + col_name for (i, col_name) in enumerate(old_high_df_cols) if i != 0] \n",
    "    new_high_df_cols = [old_high_df_cols.tolist()[0], *new_high_df_cols]\n",
    "    high_df.columns = new_high_df_cols\n",
    "\n",
    "    high_df = pd.DataFrame(high_df.groupby('image').mean().reset_index()) \n",
    "    try:\n",
    "        assert high_df.shape[0] == 3600\n",
    "    except:\n",
    "        print(data_path)\n",
    "\n",
    "    if model_type == 'PCALR':\n",
    "        pca_lr_high_df = high_df\n",
    "    elif model_type == 'PCASVC':\n",
    "        pca_svc_high_df = high_df\n",
    "    elif model_type == 'PCASVC2':\n",
    "        pca_svc2_high_df = high_df\n",
    "    elif model_type == 'CNN_LR':\n",
    "        cnn_lr_high_df = high_df\n",
    "    elif model_type == 'CNN_SVC':\n",
    "        cnn_svc_high_df = high_df\n",
    "    elif model_type == 'CNN_VggNet2':\n",
    "        cnn_vgg_high_df = high_df\n",
    "    elif model_type == 'CNN_VggNet2_SVC':\n",
    "        cnn_vgg_svc_high_df = high_df\n",
    "    elif model_type == 'CNN_AlexNet2':\n",
    "        cnn_alexnet_high_df = high_df\n",
    "    elif model_type == 'CNN_AlexNet2_SVC':\n",
    "        cnn_alexnet_svc_high_df = high_df\n",
    "    elif model_type == 'CNN_ResNet2':\n",
    "        cnn_resnet_high_df = high_df\n",
    "    elif model_type == 'CNN_ResNet2_SVC':\n",
    "        cnn_resnet_svc_high_df = high_df\n",
    "    elif model_type == 'PIXEL_SVC':\n",
    "        pixel_svc_high_df = high_df\n",
    "    elif model_type == 'PIXEL_LR':\n",
    "        pixel_lr_high_df = high_df\n",
    "\n",
    "model_list = [pixel_svc_high_df, pixel_lr_high_df,\n",
    "              pca_svc_high_df, pca_lr_high_df,\n",
    "              cnn_svc_high_df, cnn_lr_high_df,\n",
    "              cnn_alexnet_svc_high_df, cnn_alexnet_high_df,\n",
    "              cnn_vgg_svc_high_df, cnn_vgg_high_df,\n",
    "              cnn_resnet_svc_high_df, cnn_resnet_high_df]\n",
    "model_name_list = ['PIXEL_SVC', 'PIXEL_LR',\n",
    "                   'PCASVC', 'PCALR',\n",
    "                   'CNN_SVC', 'CNN_LR',\n",
    "                   'CNN_AlexNet2_SVC', 'CNN_AlexNet2',\n",
    "                   'CNN_VggNet2_SVC', 'CNN_VggNet2',\n",
    "                   'CNN_ResNet2_SVC', 'CNN_ResNet2']\n",
    "macs_df = model_list[0].merge(model_list[1], on='image')\n",
    "for i in range(2, len(model_list)):\n",
    "    macs_df = macs_df.merge(model_list[i], on='image')\n",
    "\n",
    "macs_df = macs_df.drop(macs_df.tail(1).index)\n",
    "macs_df = macs_df.set_index('image')\n",
    "macs_df.columns = model_name_list\n",
    "macs_df = macs_df.transpose()\n",
    "macs_df['19092711_64PIX_8GS_S001L1E03C7.jpg'] = macs_df['19092711_64PIX_8GS_S001L1E02C7.jpg'].values\n",
    "macs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_hyperpar = '16PIX_2GS'\n",
    "\n",
    "temp_mer_df = pd.concat([acc_df, macs_df], join='inner')\n",
    "\n",
    "temp_mer_df = temp_mer_df.T.astype(float)\n",
    "merged_df = temp_mer_df.copy()\n",
    "\n",
    "\n",
    "temp_index = []\n",
    "pix_list = []\n",
    "h_list = []\n",
    "prepar_list = []\n",
    "\n",
    "for file_name in merged_df.index:\n",
    "    split = file_name.split('.')\n",
    "    face, pix, gs, par = split[0].split('_')\n",
    "    temp_index.append(f'{pix}_{gs}_{face}_{par}') # f'{pix}_{gs}_{face}_{par}'\n",
    "    pix_list.append(pix)\n",
    "    h_list.append(f'{pix}_{gs}')\n",
    "\n",
    "merged_df['idx'] = temp_index\n",
    "merged_df['PIX'] = pix_list\n",
    "merged_df['hyperpar'] = h_list\n",
    "if chosen_hyperpar != '':\n",
    "    new_merged_df = merged_df[merged_df['hyperpar'] == chosen_hyperpar]\n",
    "else:\n",
    "    new_merged_df = merged_df\n",
    "\n",
    "temp_df = new_merged_df.groupby('idx').mean()\n",
    "\n",
    "temp_df = temp_df.sort_index()\n",
    "\n",
    "new_temp_df = temp_df.reset_index()\n",
    "\n",
    "for i in range(4, temp_df.shape[0], 5):\n",
    "    new_temp_df.loc[i+0.1] = [0]*new_temp_df.shape[1]\n",
    "    new_temp_df.loc[i+0.2] = [0]*new_temp_df.shape[1]\n",
    "new_temp_df = new_temp_df.sort_index().reset_index(drop=True)\n",
    "\n",
    "new_temp_df.index = new_temp_df['idx']\n",
    "new_temp_df = new_temp_df.iloc[:, 1:]\n",
    "new_temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_index_dict = {k:[] for k in range(1, new_temp_df.shape[1]+1)}\n",
    "for (t, col) in enumerate(new_temp_df.columns):\n",
    "    temp_col = new_temp_df[col]\n",
    "    color_index_dict[t+1] = temp_col.values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of Color Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if avg_hum:\n",
    "    l = len(sel_mc)\n",
    "else:\n",
    "    l = len(sel_ppl)\n",
    "dim = 2\n",
    "col_interval = 2\n",
    "\n",
    "gridspec = dict(wspace=0.0, width_ratios=[1, col_interval, *[1]*l, col_interval, *[1]*(new_temp_df.shape[1]-l)])\n",
    "fig, ax = plt.subplots(new_temp_df.shape[0], new_temp_df.shape[1]+3, figsize=(dim*(new_temp_df.shape[1]+3), dim*new_temp_df.shape[0]), gridspec_kw=gridspec)\n",
    "for i, idx in enumerate(new_temp_df.index):\n",
    "\n",
    "    if (idx == 0):\n",
    "        for j in range(new_temp_df.shape[1]+3):\n",
    "            ax[i][j].imshow(np.ones((*img.shape, 3))*255, cmap='gray')\n",
    "            ax[i][j].set_xticks([])\n",
    "            ax[i][j].set_yticks([])\n",
    "            ax[i][j].spines['top'].set_color('white')\n",
    "            ax[i][j].spines['bottom'].set_color('white')\n",
    "            ax[i][j].spines['left'].set_color('white')\n",
    "            ax[i][j].spines['right'].set_color('white')\n",
    "            ax[i][j].set_aspect('equal')\n",
    "\n",
    "    else:\n",
    "        if chosen_hyperpar == '':\n",
    "            par = idx\n",
    "        else:\n",
    "            pix, gs, face, par = idx.split('_') \n",
    "            # person = '19082131'\n",
    "\n",
    "        filePath = os.path.join(os.path.join(testdata_path, face), f'{pix}_{gs}_{par}.jpg')\n",
    "        assert os.path.isfile(filePath)\n",
    "        img = cv.imread(filePath, cv.IMREAD_GRAYSCALE)\n",
    "        for j in range(new_temp_df.shape[1]+3):\n",
    "            if j == 0:\n",
    "                ax[i][0].imshow(np.asarray(img), cmap='gray')\n",
    "            elif (j == 1 or j == l+2):\n",
    "                ax[i][1].imshow(np.ones((*img.shape, 3))*255, cmap='gray')\n",
    "            else:\n",
    "                if (j >= 2) and (j <= l-1):\n",
    "                    hit_rate = color_index_dict[j-1][i]\n",
    "                else:\n",
    "                    hit_rate = color_index_dict[j-2][i]\n",
    "                num_val = 1000\n",
    "                assert hit_rate >= 0 and hit_rate <= 1\n",
    "                conv_hr = hit_rate \n",
    "                conv_hr = conv_hr * (num_val - 1) \n",
    "                conv_hr = round(conv_hr)\n",
    "\n",
    "                new_conv_hr = conv_hr\n",
    "                color = sns.color_palette('Spectral', num_val)[new_conv_hr] \n",
    "                \n",
    "                ax[i][j].set_facecolor(color)\n",
    "                \n",
    "            ax[i][j].set_xticks([])\n",
    "            ax[i][j].set_yticks([])\n",
    "            ax[i][j].spines['top'].set_color('white')\n",
    "            ax[i][j].spines['bottom'].set_color('white')\n",
    "            ax[i][j].spines['left'].set_color('white')\n",
    "            ax[i][j].spines['right'].set_color('white')\n",
    "            ax[i][j].set_aspect('equal')\n",
    "\n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.savefig(os.path.join(fig_path, f'face_{chosen_hyperpar}_{test_type}.png'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = temp_df.corr()\n",
    "corr.to_csv(os.path.join(fig_path, f'corr_{test_type}_{chosen_hyperpar}.csv'))\n",
    "temp_df.to_csv(os.path.join(fig_path, f'scat_{test_type}_{chosen_hyperpar}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of PIX & GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixgs_df = macs_df.copy()\n",
    "\n",
    "hyp_lst = []\n",
    "for img in macs_df.index:\n",
    "    _, pix, gs, _ = img.split('_')\n",
    "    hyp_lst.append(f'{pix}_{gs}')\n",
    "\n",
    "pixgs_df['hyp'] = hyp_lst\n",
    "pixgs_df = pixgs_df.groupby('hyp').agg(['mean', 'sem'])\n",
    "\n",
    "pix_lst, gs_lst = [], []\n",
    "for img in pixgs_df.index:\n",
    "    pix, gs = img.split('_')\n",
    "    pix_lst.append(pix)\n",
    "    gs_lst.append(gs)\n",
    "\n",
    "pixgs_df['PIX'] = pix_lst\n",
    "pixgs_df['GS'] = gs_lst\n",
    "\n",
    "pixgs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixgs_df.to_csv(os.path.join(fig_path, f'pixgs_{test_type}.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('python39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d21f86f814c663a2839376199717de8ab40993b4cd7cf2a97226f6e7cf3338fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
